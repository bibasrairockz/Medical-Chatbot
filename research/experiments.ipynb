{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_API_ENV = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob = \"*.pdf\",\n",
    "                    loader_cls = PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\") # going back a dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 11\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = []\n",
    "n = 0 \n",
    "#  {\"id\": \"some_id\", \"values\": vector,  \"metadata\": metadata}\n",
    "metadata = {\"id\": 3056, \"description\": \"Networked neural adapter\"}\n",
    "\n",
    "for t in text_chunks:\n",
    "    d = {\"id\" : str(n), \"values\" : embeddings.embed_query(t.page_content),  \"metadata\" : {\"id\": str(n), \"description\": \"Meta\"}}\n",
    "    doc.append(d)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Length\", type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, PodSpec\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"starter-index\"\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "pc.create_index(\n",
    "  name=\"starter-index\",\n",
    "  dimension=384,\n",
    "  metric=\"cosine\",\n",
    "  spec=PodSpec(\n",
    "    environment=\"gcp-starter\"\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, PodSpec\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"starter-index\"\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in doc:\n",
    "    # print(i,type(i))\n",
    "    index.upsert(vectors = [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\" : PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model = \"model/llama-2-7b-chat.ggmlv3.q4_0.bin\", #model saved in \"model\" folder\n",
    "                  model_type = \"llama\",\n",
    "                  config = {'max_new_tokens' : 512,\n",
    "                          'temperature' : 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and therefore may help reduce the tendency to bruiseeasily. Green leafy vegetables, alfalfa, broccoli, seaweed,and fish liver oils are dietary sources of vitamin K. Othergood foods to eat would be those containingbioflavonoids, such as reddish-blue berries. These canassist in strengthening the connective tissue, which willdecrease the spread of blood and bruising. Zinc and vita-min C supplements are also recommended for this.\n",
      "Resources\n",
      "BOOKS\n"
     ]
    }
   ],
   "source": [
    "#vectorDB using chromaDB\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_community.embeddings.sentence_transformer import (\n",
    "#     SentenceTransformerEmbeddings,\n",
    "# )\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# # create the open-source embedding function\n",
    "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# # load it into Chroma\n",
    "# db = Chroma.from_documents(text_chunks, embedding_function)\n",
    "\n",
    "# # query it\n",
    "# query = \"What is achne\"\n",
    "# docs = db.similarity_search(query)\n",
    "\n",
    "# # print results\n",
    "# print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart muscle, it may help to stabilize arrhythmias. It isgentle and appropriate for home use, unlike foxglove(Digitalis purpurea ), an herb whose action on the heart is\n",
      "too potent for use without supervision by a qualified prac-titioner. Homeopathic practitioners may prescribe reme-dies such as Lachesis and aconite or monkshood ( Aconi-\n",
      "tum napellus ) to treat mild arrhythmias.\n",
      "Prognosis\n",
      "Advances in diagnostic techniques, new drugs, and\n"
     ]
    }
   ],
   "source": [
    "# query = \"What is achne\"\n",
    "# docs = db.similarity_search(query)\n",
    "\n",
    "# # print results\n",
    "# print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embeddings.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result []\n"
     ]
    }
   ],
   "source": [
    "# query = \"What are Allergies\"\n",
    "query = \"Ticker tape\"\n",
    "docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm, \n",
    "    chain_type = \"stuff\",\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents = True, \n",
    "    chain_type_kwargs = chain_type_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bibas\\medical-chatbot\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  Ticker tape is a type of paper or plastic ribbon used in ceremonial settings, such as parades and celebrations, to release confetti or streamers onto a crowd or area. It is typically made of thin strips of paper or plastic that are wound on a spool and can be unrolled quickly when needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  The Dimensions menu in Unity allows you to manipulate the size and position of objects in your scene. It is accessible through the GameObject menu, or by using the shortcut key Ctrl + Shift + Z (Windows) or Command + Shift + Z (Mac). From there, you can adjust the dimensions of an object by typing a value in the Dimensions field, or by using the slider to change the size of the object. Additionally, you can use the dimension constraints to restrict the size and position of an object within a specific range.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  I'm doing well, thanks for asking! How about you?\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
